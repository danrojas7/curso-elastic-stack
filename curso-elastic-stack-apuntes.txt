Elastik Stack
- Monitorización
- Analítica de datos
- Explotación de información

Herramientas
- Beats
- Elasticsearch
- Logstash
- Kibana

Comunicar las cuatro herramientas para monitorización y analítica de logs

Elastic stack
Es un conjunto de herramientas que está enfocada para para monitorización, analítica de logs y explotación de información. Este stack está definido por un conjunto de herramientas con una finalidad muy específica


Orígenes
Stack ELK
- Elasticsearch -> Motor de búsqueda e indexación para localizar datos
- Logstash  -> Gestión y tratamiento de información
- Kibana -> Herramienta de monitorización y de dashboard para explotar la información


Elastic stack
- Beats -> Recolección de logs
- Logstash -> Tratamiento de los logs
- Elasticsearch -> Almacenamiento de los logs
- Kibana -> consulta

Con Beats, sacar funcionalidad que antes se hacía en Logstash, toda la recolección de los logs y de información antiguamente se hacía a través de Logstash, y ahora se hace a través de beats, lo que hace que logstash siga teniendo soporte para lo que hacía antes, pero ya no se suele utilizar tanto

Beats, recolectar la información, no solamente logs
- Sistemas
- Red
- BD

Logstash, es quién se va a encargar de tratar esa información. También recolectarla, sin embargo no se va a centrar en esto, ya que para esto se encarga Beats, leer la información que hay que procesar, que hay que transformar, eliminar o añadir, o enriquecerla en cierta medida, hay que seguir haciendo cierto tipo de operaciones que se hace sobre la información, y esto es lo que permite Logstash, que es procesar la información y dejarla a nuestro gusto. Hay que tener en cuenta que la fuente de información no va a dejar la misma como a nosotros nos gustaría, en cuanto a formatos

Elasticsearch, que es donde se va almacenar la información, y donde podemos consultarla, no obstante hace más cosas, como por ejemplo indexación, y el procesamiento para indexarla

Kibana, es la herramienta que va a permitir explotar esa información, es decir ver toda la información que se ha ido guardando, pero verla de una manera mucho más global, esto nos va a permitir localizar mucho más fácil, como también una visión general sobre todo lo que tenemos.

Práctica que se va a desarrollar durante todo el curso
- Utilizar todas las herramientas del stack, y comunicarlas de la manera correcta y al final obtener un resultado satisfactorio
- Crear una aplicación que permita monitorizar los servidores donde está desplegar, y monitorizar la aplicación en si
- Aplicación en repositorio de BitBucket que genera log

- Beats, para sacar métricas tanto de red como de monitorización del sistema donde está desplegada la aplicación, y lectura de los ficheros de logs de la aplicación
- Posteriormente, se va a pasar la información a Logstash, para procesar la información, para transformarla en la medida de lo que se necesite
- Se envía a Elasticsearh para almacenarla
- Crear unos páneles de control en Kibana desde lo que podremos explotar la información, cómo está de cargado el sistema, cómo está las infertaces de red, que tráfico está moviéndose por ella, y el estado completo de la aplicación, qué errores se han producido, y si ha sufido algún tipo de ataque


Versiones de elastic
- Versión 7 de elastic
- Utilizar siempre a la última versión estable
- Versiones de trabajo diferentes que se van trabajando a lo largo del curso: 6.7, 6.5 y 7.0
- Novedades que afectan a Kibana, uso de espacios y el uso de canvas desde la versión 6.5, y en la versión 7 se incorporó el modo oscuro
- Y novedades de Elastisearh, introducción a elasticsearchSQL, lenguaje de consultas a elasticsearch basado en SQL, novedades pero a nivel interno en su motor, coordinación de clúster y optimización entre la comunicación entre los nodos

Cambios a versión 6.X a 7.0
- Copiar la carpeta ./data, a la nueva instalación de elastic
- Actualizar la configuración de elasticsearch

- Logstash, copiar las configuraciones utilizadas, y los patrones, y posteriormente arrancar el Logstash
- FileBeats, replicar la configuración de FileBeat, de las versiones anteriores


Instalación de elasticsearch
- Instalar Beats, Logstash, ElasticSearch, y or púltimo kibana
- Instalarla en los 3 sistemas operativos principales: Mac, Ubuntu y Windows
- El método es similar en los 3 sistemas operativos, es que es descargar y descomprimir lo paquetes, configurarlos mínimamente y ponerlos en marcha
- Alternativas de instalación del stack, basado en contenedores, y basado en la paquetería de los sistemas operativos
- Utilizar de ser posible la última versión estable


Instalación de Beats
- Acceder a la página https://www.elastic.co/es/downloads/
- Herramientas pequeñas para recolectar la información
        - Filebrat
        - Packetbeat
        - WinLogBeat
        - Metricbeat
        - Heartbeat
        - Auditbeat
- Descargar cualquier Beat, por ejemplo metricbeat
- Al tener acceso a la carpeta, en metricbeat se tiene los archivos README así como también el agente que lo pone en funcionamiento y los archivos de configuración
- metricbeat.yml que es una configuración de ejemplo
- metricbeat.reference.yml, fichero de toda la configuración posible que se puede hacer en el beat
- Se modifica el metricbeat.yml, para comentar el output para elasticsearch, y habilitar un output por consola:
output.console:
  pretty: true
- Se inicia el metricbeat, mediante el comando siguiente:
  $ ./metricbeat -c metricbeat.yml
- El proceso es similar para Windows, Linux y Mac, es solo descargar el beat, comentar las líneas enm el archivo de configuración correspondiente a la configuración del elastic, agregar un output de consola, y finalmente se ejecuta el servicio.



Instalación de logstash
- Descargar el Logstash desde la página de elastic:
  https://elastic.co/producs/logstash
- Para poner en funcionamiento el logstash, se debe contar por lo menos con una versión de Java 8 o posterior, para ello se comprueba mediante el comando siguiente:
  $ java -version
- Descomprimir el logstash
- En la raíz del logstash, se encuentra la carpeta bin/, con todos los ejecutables de los agentes, y la carpeta config/, en la que se encuentra los archivos de configuración del logstash, la configuración de la JVM de Java, y la configuración propia del logstash como es el caso de los pipelines
- Configuración básica para verificar que tanto el logstash esté correctamente funcionando, como también la máquina virtual de Java funcione sin inconveniente, se va a configurar un pipeline básico de entrada y salida, para verificarlo:

example.conf:

input {
   stdin {}
}


output {
   stdout {
      codec => json_lines
   }
}

- A continuación se ejecuta el logstash mediante el siguiente comando, referenciando el archivo de configuración del pipeline con su input y output:
  $ ./bin/logstash -f ./config/example.conf
- Todo lo que se digite en la entrada estándar de consola, se realiza el retorno con el formateo estándar que trae el logstash para formateo de los mensajes



Instalación del elasticsearch
- Descargar desde la página del elastic stack:
  https://www.elastic.co/downloads/elasticsearch
- Descomprimir el archivo tar.gz descargado
- En este caso, solo con la configuración básica basta, por lo tanto solamente hay que iniciar el elastic
  $ bin/elastic -d
  (El parámetro -d es para iniciar el elastic en modo servicio, por lo tanto no va a bloquear la terminal)
- Al iniciar el servidor de elastic, ahora se comprueba si arrancó correctamente, se debe acceder a http://localhost:9200
- Al comprobarse la configuración, podemos verificar que el elastic arrancó con las opciones por defecto, tanto el nombre del nodo elastic como el nombre del cluster


Instalación del kibana
- Acceder a descargar el kibana:
  https://www.elastic.co/kibana
- Descomprimir el tar.gz
- Con las configuraciones que trae por defecto, se puede iniciar sin problema el kibana
- Se debe iniciar una instancia de elastic, ya que kibana de por sí es un frontend para mostrar la información que se encuentra en elastic, y de hecho, la misma configuración se encuentra dentro de la misma base de datos
- Si el elasticsearch no se encuentra iniciado en el host y puerto por defecto (localhost:9200), queda a la espera a dicha configuración por si posteriormente se inicia una instancia elastic en el host y puerto mencionado
- Para corroborar el correcto funcionamiento del kibana, solo basta con acceder a la dirección http://localhost:5601



Instalación del elastic stack a través de docker
- Se puede acceder a través de la página, a explorar las versiones que existen de las imágenes de los distintos componentes del stack:
  https://www.docker.elastic.co/
- Se va a arrancar la parte principal del stack
- Se va a crear un fichero docker-compose.yml para crear todos juntos los componentes del stack
- Para las configuraciones básicas, se puede remitir a la documentación de la configuración en docker:
  https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html
- para iniciar el archivo docker-compose.yml, se debe ingresar el siguiente comando:
  $ docker-compose up -d
- Para visualizar los logs a fin de validar que todos los componentes hayan subido sin problema se puede verificar mediante los siguientes comandos:
  $ docker-compose logs -f elasticsearch
  $ docker-compose logs -f logstash
  $ docker-compose logs -f kibana
- Al ejecutar los contenedores con el docker-compose, se observa que los tres contenedores suben sin problema, sin embargo el logstash al no tener la configuración de pipelines en la ruta definida, detiene su ejecución, por lo tanto es correcto ya que está intentando leer los pipelines que están en la ruta acoplada con el volumen
- Para verificar el contenido dentro de la ruta donde se almacena la data en el contenedor de elasticsearch, se puede ejecutar el siguiente comando:
  $ docker exec -it elasticstack_elasticsearch_1 /bin/bash
  $ cd /usr/share/elasticsearch/data
  $ cd /usr/share/elasticsearch/config
  
  En esta ruta se encuentran entre otros, los siguientes archivos de configuración, los cuales se van a ir viendo a lo largo del curso:
  elasticsearch.yml
  jvm.options
  
  Sin embargo también hay forma de cambiar la configuración del contenedor de elasticsearch, a través de variables de entorno pasadas al contenedor a través el docker-compose.yml.
  También hay forma de exportar un volumen con un fichero de configuración, y de esta forma acoplar mediante el volumen el archivo de configuración que se encuentre en nuestra máquina host
  
  En cuando al logstash, se puede acoplar el volumen con los pipelines que se tengan definidos, de igual manera se puede aoplar el archivo de configuración mediante la metodología ya descrita
  
  En el caso de beats, dentro del sistema docker, todos los beats tienen su respectiva imagen para crearlos, de igual manera con su documentación, lo que hace falta es exportar un directorio en donde se encuentre los archivos logs de donde se debe leer la información. También se puede sobreescribir el archivo de configuración.



Otras alternativas de instalación
- Todas las herramientas no necesariamente tienen que estar corriendo todas en un mismo host en el caso que sea un proyecto en ambiente productivo, por ejemplo los beats están corriendo en los nodos en donde se encuentran los servicios que están generando los logs. Se pueden tener una o varias máquinas que se encuentran con logstash que ayudarán a recibir la información y a procesarla. De igual manera para el elastic, que puede tener un clúster en el cual pueda almacenar y responder las consultas. También se pueden tener una o varias máquinas con kibana. La manera más común es decargar los componentes necesarios, en la versión requerida y se instalan en cada nodo, aunque también es posible realizar la automatización de este proceso mediante Ansible. Aunque también existen otras formas de desplegarlos en ambientes productivo, esto es mediante el uso de contenedores.
También se pueden instalar mediante el sistema de paquetes en la distribución en Linux, por ejemplo .rpm para distribuciones basadas en RedHat, o .deb para distribuciones basadas en Debian Linux, se puede instalar mediante los gestores de paquetes yum o apt-get, aunque existe un inconveniente y es que está ligado a que dependería de las versiones que vendrían para la plataforma.
La otra alternativa sería utilizar un servicio de nube para el funcionamiento del elasticsearch y el kibana (Amazon)


Prueba de concepto
La prueba de concepto es para validar que todo lo que se instaló funcione de una manera adecuada
Se han instalado el beats, específicamente el metricbeat el cual obtiene las métricas de rendimiento del sistema operativo, el logstash, el elasticsearch y el kibana
Se va a realizar un flujo completo de interacción con el stack, se va a generar un fichero de log, el cual se va a leer mediante el filebeat, posteriormente, la información que se almacene en dicho log va a ser procesada mediante una pipeline de logstash, la cual va a procesar y enviar la información del log al elasticsearch para que se almacene, y luego se va a utilizar el kibana para consultar la información que se encuentra almacenada en el elasticsearch.

- Generar un archivo log directamente con información de prueba
- Posteriormente, se realiza la descarga del filebeat, y se configura con la entrada del filebeat en el puerto en donde está enviando la información, y el output el elasticsearch
- Se debe arrancar las herramientas en el orden siguiente, 1). Elasticsearch 2). Kibana 3). Logstash 4). Filebeat
- Iniciar el filebeat mediante el siguiente comando:
  $ ./filebeat -c filebeat.yml
  Antes se debe comentarear la sesión de elasticsearch, ya que no es necesario enviar la información directamente a elasticsearh, sino a través de logstash, por lo cual se comentarea dicha línea, y se descomentarea la línea de la sección del logstash, agregando también la información de la IP y el puerto del listener destinado para el beat desde el logstash
- Se debe agregar un index patern en kibana, para visualizar el índice creado automáticamente cuando se realizó el envío desde el filebeat, para esto se agrega el patrón logstash-*, con la selección del campo para validar fechas e histogramas a través de incorporar el campo @timestamp, con esto ya se pueden visualizar los índices disponibles y su contenido





Configuración del Beats
Objetivos
- Ver los diferentes beats, validar los beats más importantes, con énfasis en el filebeat




metricbeat

- Permite sacar métrícas de todo tipo, tanto del sistema operativo como de ciertas aplicaciones en ejecución como apache redis o kafka, se pueden extraer métricas tanto de docker y kubernets. Para cualquier propósito se puede consultar de la documentación, cómo se puede agregar funcionalidades adicionales al beat mediante los módulos
- Para el caso particular, se debe subir el logstash y el kibana, no es necesario tener arrancado el logstash, ya que la información la entrega el beat directamente procesada al elasticsearch
- Validación de módulos y templates
- Definir entradas y salidas, las entradas se pueden establecer mediante módulos, y la salida, como está por defecto al elasticsearch, no se haría necesario cambiar dicha configuración
- Es necesario habilitar la integración del metricbeat con los dashboard, para ello es necesario descomentar la línea para habilitar los dashboard kibana, así como la url con puerto del kibana
- Se debe habilitar la monitorización xpath, y el monitoreo de elasticsearch
- Para listar los módulos que vienen integrados en el metricbeat, basta mediante el siguiente comando:
  $ ./metricbeat modules list
  Este comando tiene la siguiente salida:
Enabled:
system

Disabled:
activemq
aerospike
apache
appsearch
aws
azure
beat
beat-xpack
ceph
ceph-mgr
cloudfoundry
cockroachdb
consul
coredns
couchbase
couchdb
docker
dropwizard
elasticsearch
elasticsearch-xpack
envoyproxy
etcd
golang
googlecloud
graphite
haproxy
http
ibmmq
iis
istio
jolokia
kafka
kibana
kibana-xpack
kubernetes
kvm
linux
logstash
logstash-xpack
memcached
mongodb
mssql
munin
mysql
nats
nginx
openmetrics
oracle
php_fpm
postgresql
prometheus
rabbitmq
redis
redisenterprise
sql
stan
statsd
tomcat
traefik
uwsgi
vsphere
windows
zookeeper

Para validar la configuración de cada módulo por separado, se tiene que validar las configuraciones presentes en el directorio de modules.d/, en el cual se puede habilitar, quitando la extensión sufijo .disabled, del archivo de configuración del módulo que se requiere deshabilitar, en el caso particular se modifica el beat de system.

https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-modules.html

- Para validar la configuración modificada en un archivo de configuración, para testear que se encuentre de manera correcta, se puede realizar mediante el siguiente comando:
  $ ./metricbeat test config -c metricbeat.yml
- Ahora se procede a inicializar el beat, mediante el siguiente comando:
  $ ./metricbeat -c metricbeat.yml
- Para corroborar la correcta configuración del beat, se accede a kibana en Stack Monitoring, y en la sección de Dashboard, los dashboard correspondientes a "metricbeat system"

- Se procede a validar el módulo de beat que realiza el monitoreo de docker:
- Para habilitar los módulo de docker y elasticsearch (por defecto deshabilitado), se ingresa el siguiente comando:
  $ ./metricbeat modules enable docker
  $ ./metricbeat modules enable elasticsearch




Configuración del packetbeat

- Monitorizar el tráfico de red tanto entrante como saliente, tanto a nivel de aplicación como a nivel genérico














