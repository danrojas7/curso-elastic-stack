Elastik Stack
- Monitorización
- Analítica de datos
- Explotación de información

Herramientas
- Beats
- Elasticsearch
- Logstash
- Kibana

Comunicar las cuatro herramientas para monitorización y analítica de logs

Elastic stack
Es un conjunto de herramientas que está enfocada para para monitorización, analítica de logs y explotación de información. Este stack está definido por un conjunto de herramientas con una finalidad muy específica


Orígenes
Stack ELK
- Elasticsearch -> Motor de búsqueda e indexación para localizar datos
- Logstash  -> Gestión y tratamiento de información
- Kibana -> Herramienta de monitorización y de dashboard para explotar la información


Elastic stack
- Beats -> Recolección de logs
- Logstash -> Tratamiento de los logs
- Elasticsearch -> Almacenamiento de los logs
- Kibana -> consulta

Con Beats, sacar funcionalidad que antes se hacía en Logstash, toda la recolección de los logs y de información antiguamente se hacía a través de Logstash, y ahora se hace a través de beats, lo que hace que logstash siga teniendo soporte para lo que hacía antes, pero ya no se suele utilizar tanto

Beats, recolectar la información, no solamente logs
- Sistemas
- Red
- BD

Logstash, es quién se va a encargar de tratar esa información. También recolectarla, sin embargo no se va a centrar en esto, ya que para esto se encarga Beats, leer la información que hay que procesar, que hay que transformar, eliminar o añadir, o enriquecerla en cierta medida, hay que seguir haciendo cierto tipo de operaciones que se hace sobre la información, y esto es lo que permite Logstash, que es procesar la información y dejarla a nuestro gusto. Hay que tener en cuenta que la fuente de información no va a dejar la misma como a nosotros nos gustaría, en cuanto a formatos

Elasticsearch, que es donde se va almacenar la información, y donde podemos consultarla, no obstante hace más cosas, como por ejemplo indexación, y el procesamiento para indexarla

Kibana, es la herramienta que va a permitir explotar esa información, es decir ver toda la información que se ha ido guardando, pero verla de una manera mucho más global, esto nos va a permitir localizar mucho más fácil, como también una visión general sobre todo lo que tenemos.

Práctica que se va a desarrollar durante todo el curso
- Utilizar todas las herramientas del stack, y comunicarlas de la manera correcta y al final obtener un resultado satisfactorio
- Crear una aplicación que permita monitorizar los servidores donde está desplegar, y monitorizar la aplicación en si
- Aplicación en repositorio de BitBucket que genera log

- Beats, para sacar métricas tanto de red como de monitorización del sistema donde está desplegada la aplicación, y lectura de los ficheros de logs de la aplicación
- Posteriormente, se va a pasar la información a Logstash, para procesar la información, para transformarla en la medida de lo que se necesite
- Se envía a Elasticsearh para almacenarla
- Crear unos páneles de control en Kibana desde lo que podremos explotar la información, cómo está de cargado el sistema, cómo está las infertaces de red, que tráfico está moviéndose por ella, y el estado completo de la aplicación, qué errores se han producido, y si ha sufido algún tipo de ataque


Versiones de elastic
- Versión 7 de elastic
- Utilizar siempre a la última versión estable
- Versiones de trabajo diferentes que se van trabajando a lo largo del curso: 6.7, 6.5 y 7.0
- Novedades que afectan a Kibana, uso de espacios y el uso de canvas desde la versión 6.5, y en la versión 7 se incorporó el modo oscuro
- Y novedades de Elastisearh, introducción a elasticsearchSQL, lenguaje de consultas a elasticsearch basado en SQL, novedades pero a nivel interno en su motor, coordinación de clúster y optimización entre la comunicación entre los nodos

Cambios a versión 6.X a 7.0
- Copiar la carpeta ./data, a la nueva instalación de elastic
- Actualizar la configuración de elasticsearch

- Logstash, copiar las configuraciones utilizadas, y los patrones, y posteriormente arrancar el Logstash
- FileBeats, replicar la configuración de FileBeat, de las versiones anteriores


Instalación de elasticsearch
- Instalar Beats, Logstash, ElasticSearch, y or púltimo kibana
- Instalarla en los 3 sistemas operativos principales: Mac, Ubuntu y Windows
- El método es similar en los 3 sistemas operativos, es que es descargar y descomprimir lo paquetes, configurarlos mínimamente y ponerlos en marcha
- Alternativas de instalación del stack, basado en contenedores, y basado en la paquetería de los sistemas operativos
- Utilizar de ser posible la última versión estable


Instalación de Beats
- Acceder a la página https://www.elastic.co/es/downloads/
- Herramientas pequeñas para recolectar la información
        - Filebrat
        - Packetbeat
        - WinLogBeat
        - Metricbeat
        - Heartbeat
        - Auditbeat
- Descargar cualquier Beat, por ejemplo metricbeat
- Al tener acceso a la carpeta, en metricbeat se tiene los archivos README así como también el agente que lo pone en funcionamiento y los archivos de configuración
- metricbeat.yml que es una configuración de ejemplo
- metricbeat.reference.yml, fichero de toda la configuración posible que se puede hacer en el beat
- Se modifica el metricbeat.yml, para comentar el output para elasticsearch, y habilitar un output por consola:
output.console:
  pretty: true
- Se inicia el metricbeat, mediante el comando siguiente:
  $ ./metricbeat -c metricbeat.yml
- El proceso es similar para Windows, Linux y Mac, es solo descargar el beat, comentar las líneas enm el archivo de configuración correspondiente a la configuración del elastic, agregar un output de consola, y finalmente se ejecuta el servicio.



Instalación de logstash
- Descargar el Logstash desde la página de elastic:
  https://elastic.co/producs/logstash
- Para poner en funcionamiento el logstash, se debe contar por lo menos con una versión de Java 8 o posterior, para ello se comprueba mediante el comando siguiente:
  $ java -version
- Descomprimir el logstash
- En la raíz del logstash, se encuentra la carpeta bin/, con todos los ejecutables de los agentes, y la carpeta config/, en la que se encuentra los archivos de configuración del logstash, la configuración de la JVM de Java, y la configuración propia del logstash como es el caso de los pipelines
- Configuración básica para verificar que tanto el logstash esté correctamente funcionando, como también la máquina virtual de Java funcione sin inconveniente, se va a configurar un pipeline básico de entrada y salida, para verificarlo:

example.conf:

input {
   stdin {}
}


output {
   stdout {
      codec => json_lines
   }
}

- A continuación se ejecuta el logstash mediante el siguiente comando, referenciando el archivo de configuración del pipeline con su input y output:
  $ ./bin/logstash -f ./config/example.conf
- Todo lo que se digite en la entrada estándar de consola, se realiza el retorno con el formateo estándar que trae el logstash para formateo de los mensajes



Instalación del elasticsearch
- Descargar desde la página del elastic stack:
  https://www.elastic.co/downloads/elasticsearch
- Descomprimir el archivo tar.gz descargado
- En este caso, solo con la configuración básica basta, por lo tanto solamente hay que iniciar el elastic
  $ bin/elastic -d
  (El parámetro -d es para iniciar el elastic en modo servicio, por lo tanto no va a bloquear la terminal)
- Al iniciar el servidor de elastic, ahora se comprueba si arrancó correctamente, se debe acceder a http://localhost:9200
- Al comprobarse la configuración, podemos verificar que el elastic arrancó con las opciones por defecto, tanto el nombre del nodo elastic como el nombre del cluster


Instalación del kibana
- Acceder a descargar el kibana:
  https://www.elastic.co/kibana
- Descomprimir el tar.gz
- Con las configuraciones que trae por defecto, se puede iniciar sin problema el kibana
- Se debe iniciar una instancia de elastic, ya que kibana de por sí es un frontend para mostrar la información que se encuentra en elastic, y de hecho, la misma configuración se encuentra dentro de la misma base de datos
- Si el elasticsearch no se encuentra iniciado en el host y puerto por defecto (localhost:9200), queda a la espera a dicha configuración por si posteriormente se inicia una instancia elastic en el host y puerto mencionado
- Para corroborar el correcto funcionamiento del kibana, solo basta con acceder a la dirección http://localhost:5601



Instalación del elastic stack a través de docker
- Se puede acceder a través de la página, a explorar las versiones que existen de las imágenes de los distintos componentes del stack:
  https://www.docker.elastic.co/
- Se va a arrancar la parte principal del stack
- Se va a crear un fichero docker-compose.yml para crear todos juntos los componentes del stack
- Para las configuraciones básicas, se puede remitir a la documentación de la configuración en docker:
  https://www.elastic.co/guide/en/elastic-stack-get-started/current/get-started-docker.html
- para iniciar el archivo docker-compose.yml, se debe ingresar el siguiente comando:
  $ docker-compose up -d
- Para visualizar los logs a fin de validar que todos los componentes hayan subido sin problema se puede verificar mediante los siguientes comandos:
  $ docker-compose logs -f elasticsearch
  $ docker-compose logs -f logstash
  $ docker-compose logs -f kibana
- Al ejecutar los contenedores con el docker-compose, se observa que los tres contenedores suben sin problema, sin embargo el logstash al no tener la configuración de pipelines en la ruta definida, detiene su ejecución, por lo tanto es correcto ya que está intentando leer los pipelines que están en la ruta acoplada con el volumen
- Para verificar el contenido dentro de la ruta donde se almacena la data en el contenedor de elasticsearch, se puede ejecutar el siguiente comando:
  $ docker exec -it elasticstack_elasticsearch_1 /bin/bash
  $ cd /usr/share/elasticsearch/data
  $ cd /usr/share/elasticsearch/config
  
  En esta ruta se encuentran entre otros, los siguientes archivos de configuración, los cuales se van a ir viendo a lo largo del curso:
  elasticsearch.yml
  jvm.options
  
  Sin embargo también hay forma de cambiar la configuración del contenedor de elasticsearch, a través de variables de entorno pasadas al contenedor a través el docker-compose.yml.
  También hay forma de exportar un volumen con un fichero de configuración, y de esta forma acoplar mediante el volumen el archivo de configuración que se encuentre en nuestra máquina host
  
  En cuando al logstash, se puede acoplar el volumen con los pipelines que se tengan definidos, de igual manera se puede aoplar el archivo de configuración mediante la metodología ya descrita
  
  En el caso de beats, dentro del sistema docker, todos los beats tienen su respectiva imagen para crearlos, de igual manera con su documentación, lo que hace falta es exportar un directorio en donde se encuentre los archivos logs de donde se debe leer la información. También se puede sobreescribir el archivo de configuración.



Otras alternativas de instalación
- Todas las herramientas no necesariamente tienen que estar corriendo todas en un mismo host en el caso que sea un proyecto en ambiente productivo, por ejemplo los beats están corriendo en los nodos en donde se encuentran los servicios que están generando los logs. Se pueden tener una o varias máquinas que se encuentran con logstash que ayudarán a recibir la información y a procesarla. De igual manera para el elastic, que puede tener un clúster en el cual pueda almacenar y responder las consultas. También se pueden tener una o varias máquinas con kibana. La manera más común es decargar los componentes necesarios, en la versión requerida y se instalan en cada nodo, aunque también es posible realizar la automatización de este proceso mediante Ansible. Aunque también existen otras formas de desplegarlos en ambientes productivo, esto es mediante el uso de contenedores.
También se pueden instalar mediante el sistema de paquetes en la distribución en Linux, por ejemplo .rpm para distribuciones basadas en RedHat, o .deb para distribuciones basadas en Debian Linux, se puede instalar mediante los gestores de paquetes yum o apt-get, aunque existe un inconveniente y es que está ligado a que dependería de las versiones que vendrían para la plataforma.
La otra alternativa sería utilizar un servicio de nube para el funcionamiento del elasticsearch y el kibana (Amazon)


Prueba de concepto
La prueba de concepto es para validar que todo lo que se instaló funcione de una manera adecuada
Se han instalado el beats, específicamente el metricbeat el cual obtiene las métricas de rendimiento del sistema operativo, el logstash, el elasticsearch y el kibana
Se va a realizar un flujo completo de interacción con el stack, se va a generar un fichero de log, el cual se va a leer mediante el filebeat, posteriormente, la información que se almacene en dicho log va a ser procesada mediante una pipeline de logstash, la cual va a procesar y enviar la información del log al elasticsearch para que se almacene, y luego se va a utilizar el kibana para consultar la información que se encuentra almacenada en el elasticsearch.

- Generar un archivo log directamente con información de prueba
- Posteriormente, se realiza la descarga del filebeat, y se configura con la entrada del filebeat en el puerto en donde está enviando la información, y el output el elasticsearch
- Se debe arrancar las herramientas en el orden siguiente, 1). Elasticsearch 2). Kibana 3). Logstash 4). Filebeat
- Iniciar el filebeat mediante el siguiente comando:
  $ ./filebeat -c filebeat.yml
  Antes se debe comentarear la sesión de elasticsearch, ya que no es necesario enviar la información directamente a elasticsearh, sino a través de logstash, por lo cual se comentarea dicha línea, y se descomentarea la línea de la sección del logstash, agregando también la información de la IP y el puerto del listener destinado para el beat desde el logstash
- Se debe agregar un index patern en kibana, para visualizar el índice creado automáticamente cuando se realizó el envío desde el filebeat, para esto se agrega el patrón logstash-*, con la selección del campo para validar fechas e histogramas a través de incorporar el campo @timestamp, con esto ya se pueden visualizar los índices disponibles y su contenido





Configuración del Beats
Objetivos
- Ver los diferentes beats, validar los beats más importantes, con énfasis en el filebeat




metricbeat

- Permite sacar métrícas de todo tipo, tanto del sistema operativo como de ciertas aplicaciones en ejecución como apache redis o kafka, se pueden extraer métricas tanto de docker y kubernets. Para cualquier propósito se puede consultar de la documentación, cómo se puede agregar funcionalidades adicionales al beat mediante los módulos
- Para el caso particular, se debe subir el logstash y el kibana, no es necesario tener arrancado el logstash, ya que la información la entrega el beat directamente procesada al elasticsearch
- Validación de módulos y templates
- Definir entradas y salidas, las entradas se pueden establecer mediante módulos, y la salida, como está por defecto al elasticsearch, no se haría necesario cambiar dicha configuración
- Es necesario habilitar la integración del metricbeat con los dashboard, para ello es necesario descomentar la línea para habilitar los dashboard kibana, así como la url con puerto del kibana
- Se debe habilitar la monitorización xpath, y el monitoreo de elasticsearch
- Para listar los módulos que vienen integrados en el metricbeat, basta mediante el siguiente comando:
  $ ./metricbeat modules list
  Este comando tiene la siguiente salida:
Enabled:
system

Disabled:
activemq
aerospike
apache
appsearch
aws
azure
beat
beat-xpack
ceph
ceph-mgr
cloudfoundry
cockroachdb
consul
coredns
couchbase
couchdb
docker
dropwizard
elasticsearch
elasticsearch-xpack
envoyproxy
etcd
golang
googlecloud
graphite
haproxy
http
ibmmq
iis
istio
jolokia
kafka
kibana
kibana-xpack
kubernetes
kvm
linux
logstash
logstash-xpack
memcached
mongodb
mssql
munin
mysql
nats
nginx
openmetrics
oracle
php_fpm
postgresql
prometheus
rabbitmq
redis
redisenterprise
sql
stan
statsd
tomcat
traefik
uwsgi
vsphere
windows
zookeeper

Para validar la configuración de cada módulo por separado, se tiene que validar las configuraciones presentes en el directorio de modules.d/, en el cual se puede habilitar, quitando la extensión sufijo .disabled, del archivo de configuración del módulo que se requiere deshabilitar, en el caso particular se modifica el beat de system.

https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-modules.html

- Para validar la configuración modificada en un archivo de configuración, para testear que se encuentre de manera correcta, se puede realizar mediante el siguiente comando:
  $ ./metricbeat test config -c metricbeat.yml
- Ahora se procede a inicializar el beat, mediante el siguiente comando:
  $ ./metricbeat -c metricbeat.yml
- Para corroborar la correcta configuración del beat, se accede a kibana en Stack Monitoring, y en la sección de Dashboard, los dashboard correspondientes a "metricbeat system"

- Se procede a validar el módulo de beat que realiza el monitoreo de docker:
- Para habilitar los módulo de docker y elasticsearch (por defecto deshabilitado), se ingresa el siguiente comando:
  $ ./metricbeat modules enable docker
  $ ./metricbeat modules enable elasticsearch




Configuración del packetbeat

- Monitorizar el tráfico de red tanto entrante como saliente, tanto a nivel de aplicación como a nivel genérico
- Se debe descargar de la siguiente URL:
  https://www.elastic.co/downloads/beats/packetbeat
- Se debe centrar en tres aspectos: el input, de donde va a tomar la información, el output, donde la va a enviar a almacenar, y temas de monitorización
- En el input, se tiene que determinar qué interfaz se va a monitorizar
- activar la monitorización xpack, y la de elasticsearch
- habiltar la salida u output a kibana y elasticsearch, también se debe activar los dashboard de kibana 
- Mediante el siguiente comando, se puede determinar la interfaz en la cual se va realizar la monitorización (input):
  $ ./packetbeat devices
  La salida del comando es el siguiente:
  
  0: eth0 (No description available) (192.168.1.12 ::cd6c:5f51:6b6f:b03b ::3e44:df0d:943c:628 fe80::38a0:e7c1:8c38:b3e9)
  1: any (Pseudo-device that captures on all interfaces) (Not assigned ip address)
  2: lo (No description available) (127.0.0.1 ::1)
  3: wlan1 (No description available) (Not assigned ip address)
  4: nflog (Linux netfilter log (NFLOG) interface) (Not assigned ip address)
  5: nfqueue (Linux netfilter queue (NFQUEUE) interface) (Not assigned ip address)

  Se puede establecer la interfaz por el nombre o por el índice asignado
- Se puede monitorizar mendiante los protocolos y puertos por servicios para monitorización, por ejemplo mysql, http, dns
- Se pueden monitorizar a nivel de procesos, por ejemplo el tráfico generado por el proceso de mysql
- Inicializar el servicio de packetbeats, para ello primero se debe realizar la comprobación del fichero de configuración mediante el comando siguiente:
  $ ./packetbeat test config -c packetbeat.yml
- Al inicializarlo mediante el comando siguiente, se obtiene un error, en el cual se especifica que el usuario que realiza la ejecución del proceso de packetbeat no tiene los permisos suficientes para monitorizar las interfaces, al menos esto sale en los sistemas basados en UNIX:
  $ ./packetbeat -c packetbeat.yml
  
  Por lo tanto se tiene que ejecutar desde un usuario que tenga el permiso de hacer sniffing para el monitoreo de las interfaces, o también desde el root mediante sudo, siempre y cuando el root también sea el propietario del archivo de configuración:
  $ sudo ./packetbeat -c packetbeat.yml
- Se puede observar el resultado de la ejecución del beat accediendo a kibana, en el de Flows, en el cual únicamente va a tener información, si no se tiene ningún otro servicio del sistema habilitado




Configuración del heartbeat
- Este beat permite conocer el estado de los servicios en funcionamiento, con esto permite conocer si un servidor o base de datos se encuentra en funcionamiento o se encuentra caída
- Nagios, similar a dicha herramienta
- Se debe descomprimir el tar.gz
- Configurar entrada de datos y salida
- La configuración de datos se debe configurar a elasticsearch de salida
- Lo diferente en este beat son los monitores, en los que se pueden monitorear en URLs a servicios http (aplicaciones web)
- Soporta servicios TCP, en caso de comprobar servicios smtp y bases de datos, para comprobar si un determinado servicio a un determinado puerto
- También soporta monitoreo icmp (ping)
- Se puede definir un schedule, por defecto se puede dejar de la manera tradicional, o también se puede utilizar la sintáxis de cron
- Se testea el archivo de configuración, mediante el siguiente comando:
  $ ./heartbeat test config -c heartbeat.yml
- Y se ejecuta mediante el siguiente comando:
  $ ./heartbeat -c heartbeat.yml
- Para validar la información enviada por el beat heartbeat, se debe consultar en kibana la sección correspondiente de uptime, para consultar las aplicaciones que se encuentran arriba como también las que se encuentran caídas




Configuración del Filebeat
- Es uno de los beats más compejos
- Análisis del logs
- Cómo utilizar los módulos de los logs preconfigurados (Apache, IIS)
- Configuraciones de filebeat para optimización en su funcionamiento


- Para analizar el log de una aplicación personalizada, se puede descargar una aplicación demo que genera logs de forma aleatoria, en la siguiente URL:
  https://bitbucket.org/kuroobicoders/log-generator/downloads/
- Despliega una ayuda que muestra el programa respecto a las entradas requeridas para generar el log
  $ java -jar log-generator-1.0.jar -h
- Lo primero que se tiene que realizar es validar el log de la aplicación a la cual se requiere monitorear, para ello ser va a generar una traza aleatoria de logs mediante el programa del componente JAR mediante el comando:
  $ java -jar ./log-generator-1.0.jar -l 50 -d 0
- Se debe evitar la configuración de logs por el nombre explícito del log, ya que en algunos casos el log puede rotar. Para el caso de la aplicación de los logs, se puede ejecutar con el siguiente comando, el cual genera las trazas de manera indefinida para verificar si el log va a rotar
  $ java -jar ./log-generator-1.0.jar -l -1 -d 0
- Para asegurar que el filebeat tome los logs tanto el actual como el log que ya rotó, se puede hacer mediante la máscara siguiente: log-generator*.log, en caso de validar que todos los logs los esté tomando de manera correcta, se puede comprobar mediante un ls:
  $ ls -lah log-generator*.log
- Inicialmente para asegurar si el log se está recolectando de manera correcta, se va a comentaerar el output del logstash, y se va a agregar uno de consola, ya que es objetivo en este paso en particular validar que el log se está recolectado de manera correcta
- Para ejectar el filebeat, y validar que se está recolectando el log, se puede validar mediante la ejecución del filebeat, con el comando:
  $ ./filebeat -c ./filebeat.yml
- Para asegurar que los logs se están recolectando, se ejecuta la aplicación:
  $ java -jar ./log-generator-1.0.jar -l 20 -d 1000
- Los mensajes de DEBUG, no deberían ir al logstash (las trazas de depuración), para ello se pueden configurar para recoger las trazas necesarias mediante inclusión o exclusión de trazas mediante filtros de patrones
- Se debe realizar modificaciones adicionales, para que se obtengan las trazas de error de varias líneas en el caso de los stacktrace, para queden en un solo evento de filebeat, para ello filebeat proporciona un soporte de evento multilínea, en el caso de que un evento de log no inicie mediante un evento de traza, se debe adjuntar a un evento anterior, para ello se va a utilizar una expresión regular
- Página para testear las expresiones regulares:
  https://rubular.com/
- Con la expresión regular, se puede definir los eventos de traza con los cuales inicia un nuevo evento:
  ^(DEBUG|INFO|ERROR|TRACE|FATAL|WARNING).*
- Se debe negar la expresión, para indicar que las líneas no identificadas mediante un evento de traza, por ejemplo en un stacktrace, concatene al evento anterior hasta que exista un nuevo evento de traza


Módulos para monitoreo de logs preconfigurados en filebeat
- Para visualizar los módulos disponibles en filebeat
  $ ./filebeat modules list
- Para habilitar un módulo, se puede mediante el comando
  $ ./filebeat modules enable logstash system

  Para el módulo de system, va a recolectar las métricas del sistema, y este es únicamente para sistemas basados en UNIX, por lo tanto si se utiliza desde Windows, no va a recopilar ningún tipo de información
- Para el módulo system, el automáticamente tomará la información en base al sistema operativo, y a partir de ahí va a determinar las rutas estándar en donde se encuentran las rutas estándar de los logs, de igual manera para el logstash.
- Para el caso particular del módulo de logstash, lo determina en base a si fue instalado en el sistema con base en algún sistema de paquetería, o lo determinará en base la instalación y la ruta del ejecutable instalado en Windows, para el caso particular de los ejercicios realizados, no va a funcionar ya que no es una instalación en rutas estándar, por lo tanto es necesario configurar las rutas de manera explícita. 
- Para el caso particular de la configuración de los módulos para logs preconfigurados, no requieren procesamiento a través del logstash, sino que pasan directamente al elasticsearch. Lo que se suele hacerse normalmente, es monitorear los logs de las aplicaciones personalizadas a través de un filebeat apuntando este mismo a logtsash para el procesamiento de los logs en el mismo, y monitorear el sistema mediante módulos y monitorización, a través de otro filebeat que apunte directamente en su output al elasticsearch.
- Se inicia el filebeat mediante el comando:
  $ ./filebeat -c filebeat.yml
- En kibana, se puede validar la monitorización del filebeat, como también con los dashboard configurados para filebeat como los SSH login attemps, Sudo attemps, etc.



Configuración avanzada del filebeat
- Validación de los diferentes tipos de inputs
  stdinput
  docker
  redis
  UDP
  TCP
- Se debe configurar, ya que en el apartado de logstash se requiere tener habiitado el output hacia el logstash desde el filebeat, para ello se debe deshabilitar el setup del kibana y del elasticsearch, para habilitar el logstash, también es importante resaltar que se pueden definir múltiples host de logstash, siempre y cuando estas instancias estén activas en un modo cluster
- El pipelining, es una configuración en la cual se puede establecer el número simultáneo de envíos de trazas, y que van a quedar en espera hasta la respuesta, se debe tener sumo cuidado en la configuración de esta propiedad, ya que un pipelining alto puede saturar el logstash, y más si hay más beats reportando simultáneamente el logstash; por otro lado la propiedad workers, hace referencia al número de hilos del procesador simultáneos para uso del reporte hacia el logstash, con lo cual también se tiene que tener cuidado que queden hilos disponibles para otros procesos si es el caso
- Se debe optimizar el trabajo que realiza el filebeat, para ello se debe deshabilitar las exclusiones, ya que en dado caso es necesario para cada traza evaluarla con las exclusiones para validar si aplican o no, pero si se deshabilita para el caso particular de los debugs, se enviarían todas las trazas, pero otro lado aumentaría el tráfico de red, por lo cual no hay una formula mágica que funcione para todos los casos


Otros beats
- WinlogBeat: Se utiliza para monitorizar sistemas windows, en este caso el beat sirve obtener todos los eventos que se generan en Windows, y generar unos dashboard de manera similar a los otros beats ya vistos
- Auditbeat: Hace lo mismo para monitorizar de manera similar al Winlogbeat, pero para sistemas linux, da métricas exclusivas del sistema operativo
- Community beats: beats provistos por la misma comunidad, sin soporte de la empresa elastic
- Con la librería commonbeat, se utiliza para desarollar sus propios beats



Logstash inputs
- Pieza más compleja del stack, ya que permite realizar muchas más cosas en los logs
- Tomar la información de entrada para procesarla

Pipeline del logstash
- Herramienta para el tratamiento puro de logs
- Es necesario una fuente de entrada, que en este caso va a ser beats, que pueden tener como fuente de información los logs de las aplicaciones desarrolladas, así como también de otras fuentes mediante beats o módulos del filebeat, como puede ser la información generada desde un redis, bases de datos, servidor de correo electrónico, desde amazon web services, el mismo elasticsearch, sistemas de colas como RabbitMQ y Kafka.
- Para la salida también se puede direccionar a direferentes herramientas como las ya mencionadas, aunque en el curso se va a tener principal énfasis en elasticsearch
- Internamente, el pipeline de logstash está compuesto por un input, el cual es la entrada de la cual se va a recibir los datos; el filter, son todas las transformaciones que se van a realizar sobre los datos, a campos que sean entendibles, añadir campos y añadir cierta lógica de negocio para sacar de los campos información extra o enriquecerlo; el output: que es la salidaa los múltiples destinos ya descritos, en este caso va a ser el elasticsearch
- Codec: es una trasformación en la salida que va a hacer el logstash con la información que estemos trabajando, para tranformar en un formato de salida. Por ejemplo el codec JSON para transformar la salida a JSON. Hay múltiples codec para transformar las salidas a diferentes formatos


Input stdin
- Entrada por consola
- No es utilizado en un escenario productivo, simplemente sirve para labores de testeo del logstash, ya que solamente se requiere configurar este input, y no para no involucrar otros componentes de la integración  en el testeo de logstash
- Se inicia logstash con la configuración definida incialmente, para testear que el logstash continúe funcionando correctamente:
  $ ./logstash -f ./config/example.conf
- En el ejemplo presentado inicialmente en el example.conf, en la salida definida, se encuentra que la misma ya hace el uso de un codec, por el cual se define que la salida no se va a manejar tal cual logstash la capturó, sino que va a darle un formato de JSON
- Si se comentarea la línea de salida en donde está definido el codex explícito en el archivo de configuración example.conf del logstash, se encuentra que al arrancarlo de nuevo da una salida estándar a la cual está configurada por defecto el logstash (un JSON).
- Uno de los codecs más usados es el de multiline en la entrada, el cual se puede usar de la siguiente manera, y de forma similar a como se estaba usando en la configuración del filebeat:

input {
   stdin {
      codec => multiline {
         pattern => "fin"
         negate => "true"
         what => "next"
      }
   }
}
output {
   stdout {
      #codec => json_lines
   }
}

- El otro codec usualmente empleado en el stdin, es el de JSON, el cual se configurade la siguiente manera (se comentarea el codec de multiline):
input {
   stdin {
      # codec => multiline {
      #    pattern => "fin"
      #    negate => "true"
      #    what => "next"
      # }
      codec => json
   }
}
output {
   stdout {
      #codec => json_lines
   }
}

- Inicialmente se realiza la prueba con la línea del codec comentareada, y se hace una prueba ingresando un JSON en el stdin una vez iniciado el logtsash, con lo cual se puede observar que en el output lo toma como un string JSON, agregando caracteres de escape para el caso de las comillas, ya que logstash no reconoce que lo que le está ingresando en este caso un JSON, por esta razón lo reconoce como una cadena de texto más
- En caso de que la información enviada en el input no sea un JSON, con el codec de entrada JSON empleado, se encuentra que aunque el logstash lo procesa, el tag agregado es como tal un _jsonparsefailure
- Para referirse a documentación de los codecs disponibles, se puede consular la URL de logstash:
  https://www.elastic.co/guide/en/logstash/current/codec-plugins.html
- Este codec es más usado en el apartado de testing para saber cómo se comporta con distintas entradas y distintos codecs



Input file
- Es el input hasta hace poco tiempo más usado, porque antes de la existencia de filebeat, se usaba para obtener la información de los logs directamente
- Permite leer archivo de logs directamente
- En algunas arquitecturas, no se hace necesario emplear un recolector de logs externo al logstash, con lo cual con el input file del logstash basta y sobra
- En la configuración del input file en el fichero de configuración, nos encontramos que a diferencia del filebeat, se hace necesario definir el path de los archivos de logs de manera absoluta, no de manera relativa:
- Se puede incluir la configuración de exclude, para que no utilice los archivos de logs definidos en esta regla
- se puede usar la opción del start_position, para definir si se va a leer el archivo de log desde el inicio, o directamente al final
- Otra opción muy popular, es la sincedb_path, indica la ruta del fichero que va a guardar el estado de lectura el el cual va el logstash, para asegurar que solamente la primera vez que solo la primera vez que se lea el archivo lo realice desde el principio, para asegurar que cada vez que vaya a leer el contenido del archivo no lo realice desde el principio propiciando a que se dupliquen las trazas del log

input {
   #stdin {
      # codec => multiline {
      #    pattern => "fin"
      #    negate => "true"
      #    what => "next"
      # }
      # codec => json
   #}
   file {
      path => "/opt/training/elastic-stack/logs/log-generator*.log"
      #exclude => "*.gz"
      start_position => "beginning"
      sincedb_path => "/opt/training/elastic-stack/logs/log-generator.sincedb"
   }
}
output {
   stdout {
      #codec => json_lines
   }
}

- Para validar si la configuración del archivo de configuración es correcta, se puede hacer mediante el comando siguiente, de manera similar a como se realiza con los beats:
  $ ./bin/logstash -t -f ./config/example.conf
- Al iniciar el logstash, se observa que obtiene las trazas de logs de los archivos que coinciden con máscara ingresada en el archivo de configuración, de igual forma se pueden generar nueva mediante el jar de log-generator:
  $ java -jar ./log-generator-1.0.jar -l 200 -d 0
- Sin enbargo nos encontramos con un problema similar al que se tuvo en filebeats, el cual es que no está tomando la información de las trazas multilínea, para ello se hace la configuración del codec multiline:

input {
   #stdin {
      # codec => multiline {
      #    pattern => "fin"
      #    negate => "true"
      #    what => "next"
      # }
      # codec => json
   #}
   file {
      path => "/opt/training/elastic-stack/logs/log-generator*.log"
      #exclude => "*.gz"
      start_position => "beginning"
      sincedb_path => "/opt/training/elastic-stack/logs/log-generator.sincedb"
      codec => multiline {
         pattern => "^(DEBUG|INFO|ERROR|TRACE|FATAL|WARNING).*"
         negate => "true"
         what => "previous"
      }
   }
}
output {
   stdout {
      #codec => json_lines
   }
}


- En el caso anterior con las modificaciones realizadas, ahora procedemos a validar el archivo .sincedb, el cual tiene la metadata en la cual el logstash lleva procesado del archvo, si queremos que vuelva a procesar el archivo nuevamente, con es en este caso, ahora se procede a eliminar dicho archivo y a relanzar el logstash:
  $ rm -Rfv log-generator.sincedb
- Con esto, al volver a ejecutar el logstash, ya logra el correcto procesamiento de los eventos multilínea del log, de acuerdo a la configuración establecida en el code multiline, configurado de manera similar a la configuración del filebeat


Input beats
- Desde que beats empezó a ser parte del elastic stack, se ha convertido en un estándar en la recolección de la información, y envío a elasticsearch
- Alguna de esta información enviada por los beats, debe ser procesada, y de esto se encarga el logstash
- Dado lo anterior, el plugin de beats del logstash se ha convertido en uno de los más utilizados
- El plugin de beats es uno de los más sencillos de configurar en el logstash
- Lo primero que se tiene que hacer es crear un nuevo archivo de configuración, ya no se va a utilizar el de example.conf
- También la configuraciones importantes, suelen ser las de el cifrado ssl, con lo cual se le puede adicionar la configuración ssl en el mismo input, de acuerdo a la documentación de la página de elastic:
  https://www.elastic.co/guide/en/logstash/current/plugins-inputs-beats.html
  
input {
  beats {
    port => "5044"
    host => "0.0.0.0"
    ssl => "false"
  }
}

output {
  stdout {
    #codec => json_lines
  }
}
  
- Anteriormente, ya que no se soportaban múltiples pipelines, era necesario definir para cada tipo de log reportarlo en listeners distintos de logstash, por lo tanto era necesario definir en cada puerto el pipeline a utilizar. Al día de hoy esto ya no es necesario con el soporte nativo del logstash de múltiples pipelines
- Para iniciar el logstash con la nueva configuración, se realiza mediante el comando
  $ ./bin/logstash -f ./config/log-generator.conf
  
  Y para testear la sintáxis del archivo de configuración, se puede hacer mediante el comando
  $ ./bin/logstash -t -f ./config/log-generator.conf
- Se deben deshabiliar los módulos habilitados en el filebeat, ya que el beat se va a utilizar para propósitos de monitorear los logs personalizados, y no van a ser de propósito general. Por lo tanto se debe hacer con los comandos
  $ ./filebeat modules disable system
  $ ./filebeat modules disable logstash
- Se procede a arrancar logstash:
  $ ./bin/logstash -f ./config/log-generator.conf
- Finalmente se procede a arrancar beats:
  $ ./filebeat -c ./filebeat.yml
- Y se revalida mediante una prueba con el jar que genera los logs, y se validan las salidas de consola de la información escrita en el log por la aplicación jar:
  $ java -jar ./log-generator-1.0.jar -l 200 -d 0



Otros plugins de entrada
- Para transformación de información al margen del elasticstack
- Para remitirse a otros plugins de input, se puede remitir a la documentación del logstash
  https://www.elastic.co/guide/en/logstash/current/input-plugins.html
  Amazon Web Services
  cloudwatch
  s3
  colas de amazon
  
  Bases de datos
  couchdb
  sqlite
  
  dead_letter_queue -> Eventos no enviados a elasticsearch
  
  elasticsearch -> Ejecutar querys en elasticsearch, con información para ser procesada (elasticsearch como input)
  jdbc -> consultas a bases de datos
  
  exec -> Scripts de sistema operativo
  colas -> jms, kafka, rabbitmq, redis (como cola)
  log4j
  
  github
  syslog




Logtrash filters
- Obtención de la información, tratar, transformar y enriquecer, mediante filtros en logstash
- Logstash es visto como una ETL, que lo que hace es la obtención, transformación de información
- Otras opciones de logstash



Filter Grok: Básico
- Plugins para filtrar, en el caso particular el plugin grok
- Es el más usado de logstash
- Es el más complejo
- Descomponer en componentes que puedan ser tratados en las partes que nos interesan
- Tiene una serie de patrones para particionar la información
- Puede utilizarse también expresiones regulares
- Un plugin que consume muchos recursos en la plataforma de logstash
- En el mundo ideal, los logs deberían venir en formato JSON, con esto no tendría que realizarse ningún tipo de groking, y se pasarían estos logs directamente a elasticsearch. Sin embargo en el mundo real, los ficheros de logs nunca vienen en JSON vienen en formato de texto, con sus patrones y particularidades
- Es necesario analizar los ficheros de logs los cuales se van a enviar a logstash
- Para validar los logs, y los patrones se puede ingresar a la herramienta grok debugging, de kibana, en los devtools
- Similar a la herramienta vista anteriormente, también se puede utilizar la herramienta presente en la página siguiente:
  https://grokdebug.herokuapp.com/
  Esta tiene además también documentación de ayuda de los distintos patrones utilizados en grok
  https://grokdebug.herokuapp.com/patterns
- Una vez definido el patrón grok, como se puede ver a continuación, se puede iniciar el logstash y a continuación el filebeat

input {
  beats {
    port => "5044"
    host => "0.0.0.0"
    ssl => "false"
  }
}

filter {
  grok {
    match => {
      "message" => "%{WORD:level} %{TIMESTAMP_ISO8601:date} \[%{WORD:thread}\] %{JAVACLASS:class} - %{WORD:type}\|%{NUMBER:status}\|%{USERNAME:user}\|%{IP:ipAddress}"
    }
  }
}

output {
  stdout {
    #codec => json_lines
  }
}

- Seguidamente para probar el patrón, se puede ejecutar la aplicación para generar los logs:
  $ java -jar ./log-generator-1.0.jar -l 10 -d 1000
- En determinadas trazas de logs que no coinciden con el grok definido para el tipo LOGIN definida en el ejercicio, no va a parsear la información del log en cuyo caso va a salir un error de tipo _grokparsefailure




Filter Grok: Avanzado
- Realizar la creación de los patrones para interpretar el resto de las entradas de los logs

input {
  beats {
    port => "5044"
    host => "0.0.0.0"
    ssl => "false"
  }
}

filter {
  grok {
    match => {
      "message" => [
        "%{WORD:level} %{TIMESTAMP_ISO8601:date} \[%{WORD:thread}\] %{JAVACLASS:class} - %{WORD:type}\|%{NUMBER:status}\|%{USERNAME:user}\|%{IP:ipAddress}",
        "%{WORD:level} %{TIMESTAMP_ISO8601:date} \[%{WORD:thread}\] %{JAVACLASS:class} - %{WORD:type}\|%{NUMBER:duration}\|%{DATA:action}\|%{WORD:status}\|%{USERNAME:user}",
        "(?m)%{WORD:level} %{TIMESTAMP_ISO8601:date} \[%{WORD:thread}\] %{JAVACLASS:class} - %{DATA:description}\|%{GREEDYDATA:stacktrace}"
      ]
    }
  }
}

output {
  stdout {
    #codec => json_lines
  }
}



Filter Grok: Usos avanzados
- Creación de patrones personalizados mediante expresiones regulares mediante (?<stacktrace>regexp)
  "(?m)%{WORD:level} %{TIMESTAMP_ISO8601:date} \[%{WORD:thread}\] %{JAVACLASS:class} - %{DATA:description}\|(?<stacktrace>.*)"
- En ciertos casos, cuando en los logs existe más de una vez el mismo patrón, es necesario agruparlo en un custom pattern, definido de la forma siguiente
  COMMON_LOG %{WORD:level} %{TIMESTAMP_ISO8601:date} \[%{WORD:thread}\] %{JAVACLASS:class} - 
  Esto es útil para agrupar en un solo patrón los patrones iguales que se repiten en cada uno de los patrones empleados
- Para hacer referencia al patrón COMMON_LOG, se puede hacer de la siguiente manera:
  (?m)%{COMMON_LOG}%{DATA:description}\|%{GREEDYDATA:stacktrace}
- Para omitir algún campo específico para almacenamiento, basta con quitar de la definición del nombre del campo después de los dos puntos, en el siguiente ejemplo ya no se va a tener el campo description en cuenta para almacenar
  (?m)%{COMMON_LOG}%{DATA}\|%{GREEDYDATA:stacktrace}
- Se puede definir el patrón mediante la directiva
  pattern_dir => "patterns"
  En la cual se establece el directorio en donde van a estar almacenados los patrones, solamente basta con crear un archivo con el mismo nombre del archivo de configuración empleado, y la extensión patterns: log-generator.patterns, en el archivo pueden existir uno o varios patrones, de igual manera pueden existir uno o n ficheros de patrones definidos, y con la directiva pattern_dir, se le indicaría al logstash que lea todos los archivos de patrones incluídos dentro de ese directorio
  
input {
  beats {
    port => "5044"
    host => "0.0.0.0"
    ssl => "false"
  }
}

filter {
  grok {
    pattern_dir => "patterns"
    match => {
      "message" => [
        "%{COMMON_LOG}%{WORD:type}\|%{NUMBER:status}\|%{USERNAME:user}\|%{IP:ipAddress}",
        "%{COMMON_LOG}%{WORD:type}\|%{NUMBER:duration}\|%{DATA:action}\|%{WORD:status}\|%{USERNAME:user}",
        "(?m)%{COMMON_LOG}%{DATA:description}\|%{GREEDYDATA:stacktrace}"
        # "(?m)%{COMMON_LOG}%{DATA:description}\|(?<stacktrace>.*)"
      ]
    }
  }
}

output {
  stdout {
    #codec => json_lines
  }
}



























